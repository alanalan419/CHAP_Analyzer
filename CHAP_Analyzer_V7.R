#set your working directory to your desktop (or wherever you are going to store your files)
setwd('/Users/alanrodriguez/Desktop')
library(dplyr)
#Read in the chap_stats information RUN IT TWICE. INGNORE ERR
#Your Path to Chap_Stats
Chap_Stats = read.delim('/Users/alanrodriguez/Google Drive/Shared drives/Ohalo Molecular Bio/chap/SRU080-custom/chap.stats.tsv', sep = '\t')
#Read in the Chap information
#Your Path to Chap
Chap = read.delim('/Users/alanrodriguez/Google Drive/Shared drives/Ohalo Molecular Bio/chap/SRU080-custom/chap.tsv', sep = '\t')
#give the chap columns names
colnames(Chap) = c("lib", "col2", "col3", "col4", "col5", "col6", "col7")
#designate lib as your "key" so that you can merge chap and chap stats data
key_column = "lib"
#merge chap and chap stats data.
Merged_Chap = merge(Chap, Chap_Stats[,c("plant_material", "aliases", "pedigree", "DNA", "lib","project")], by = key_column, all.x = FALSE)# fix BUG HERE Duplicates VALUES

#View(Merged_Chap)
#remove duplicated rows generated by merge()
Merged_Chap$Combined = paste(Merged_Chap$lib, Merged_Chap$col2, Merged_Chap$col3, Merged_Chap$col4, Merged_Chap$col5, 
                             Merged_Chap$col6, Merged_Chap$col7, Merged_Chap$plant_material,
                             Merged_Chap$aliases, Merged_Chap$pedigree, Merged_Chap$DNA)
#create a table with the PRS and DNA target merged. Use this to extract only legitimate rows. 
Merged_Chap$PRS_DNA = (paste(Merged_Chap$col2,Merged_Chap$DNA))
#Read in the current layout of DNA and PRS numbers from our data repository in Benchling.
PRS_Key = read.csv('PRS_Key.csv')
#Use PRS_Key to pull only combinations of PRS and DNA that should exist. The merge function used above generates false reads bc it 
#combines makes duplicate reads for reads with PRS and DNA not matching for example. PRS155 is for StVinv but once the two chap files
#are merged a false read is created that has PRS725 which correlates to StBAM9 but reports StVinv. Not sure why this happens and am
#adressing it here. I may be able to refine the code above so this is not an issue but for now this is the solution. 
Merged_Chap = Merged_Chap %>%
  inner_join(select(PRS_Key,PRS_DNA), by = c('PRS_DNA' = 'PRS_DNA'))
#Filtered any combination that is not a real read for example "PRS078 StSpo11" 
#this read is a duplicate of "PRS078 StRec8" and is not real.
#so basically here you are using the Legit_Read_Key to keep only the real reads, anything else with 
#those PRS is removed

# PED_target is creating a unique PED ID by Target that way you can link ddPCR results to ISeq results in Phase IV.
Merged_Chap$PED_Target = paste(Merged_Chap$plant_material,"_",Merged_Chap$DNA)
#paste adds an unwanted space between PED ID _ Target. gsub() substitutes the spaces (think of it like CTRL + F and Replace)
Merged_Chap$PED_Target = gsub(" _ ", "_", Merged_Chap$PED_Target)
#Extracts SRU# from Project column
Merged_Chap$SRU = sub("_.*","",Merged_Chap$project)
#Extracts Plate name from Aliases column
Merged_Chap$Plate_Name = sub("_.*","",Merged_Chap$aliases)
#making a column for future use when I improve Guide screen calling so that each guide is called based on its proximity to the recorded deletion.
Merged_Chap$PRS_RES_DEL = NA
#Remove Everything that is duplicated
Merged_Chap = Merged_Chap[!duplicated(Merged_Chap$Combined),]
#View(Merged_Chap)
#extract the bp up to the deletion
Merged_Chap$Left = as.integer(sub("=.*", "", Merged_Chap$col5))
#extract the deletion size
# Create a data frame with the sample data

# Function to extract the numbers between '=' and 'D'
extract_numbers <- function(text) {
  numbers <- unlist(regmatches(text, gregexpr("(?<=\\=)\\d+(?=D)", text, perl=TRUE)))
  if (length(numbers) >= 2) {
    return(paste(numbers[1], numbers[2], sep = "+"))
  } else if (grepl("\\d+D\\d+", text)) {
    numbers <- gsub(".*=(\\d+)D.*", "\\1", text)
    return(paste(numbers, "NA", sep = ","))
  } else {
    return(NA)
  }
}

# Apply the function to all values in the data frame
Merged_Chap$deletion <- sapply(Merged_Chap$col5, extract_numbers)

# Remove "NA" values in the Extracted_Numbers column and replace ",NA" with an empty string
Merged_Chap$deletion <- gsub(",NA", "", Merged_Chap$deletion)
New_table = Merged_Chap

# Add in LIB ID_Target to get a column you can calculate Read % with
New_table$LIB_Target_PRS = (paste(New_table$lib,New_table$DNA,New_table$col2))
New_table = New_table %>% 
  group_by(LIB_Target_PRS) %>%
  mutate(Reads_per_target = sum(col4))
#View(percent)
#get percent representation of reads per libID
New_table$read_percent = round((New_table$col4/New_table$Reads_per_target)*100,1)
#Next two code blocks are to get all the reads for a particular target ordered from largest to smallest
New_table = New_table %>%
  arrange(desc(lib),desc(DNA),desc(col2),desc(col4))


#############################################################
#The following code would filter based on a 10% read count for a given lib ID for example if there are 100 reads total and row 1 had 25 reads it accounts for 25% of the seen reads. anything less than 10% would be removed. 
#percent = New_table
#Calculate the sum of column4 based on LibID
#percent = percent %>% 
#  group_by(lib) %>%
#  mutate(Sum_per_Lib = sum(col4))
#View(percent)
#get percent representation of reads per libID
#percent$read_percent = round((percent$col4/percent$Sum_per_Lib)*100,1)
#New_percent = subset(percent, read_percent >= 10)
#New_percent = subset(New_percent, col4>= 30)
##############################################################

# Function to count the occurrences of 'D', 'X', and 'I'
count_characters <- function(text) {
  counts <- table(strsplit(gsub("[^DXI]", "", text), ""))
  counts_str <- paste(counts["D"], counts["X"], counts["I"], sep = ",")
  return(counts_str)
}

# Apply the function to the Original column in the data frame
New_table$Character_Counts <- sapply(New_table$col5, count_characters)


#Function to count the occurrences of 'D', 'X', and 'I' separately
count_characters <- function(text) {
  counts <- table(strsplit(gsub("[^DXI]", "", text), ""))
  counts_D <- ifelse("D" %in% names(counts), counts["D"], 0)
  counts_X <- ifelse("X" %in% names(counts), counts["X"], 0)
  counts_I <- ifelse("I" %in% names(counts), counts["I"], 0)
  return(c(D = counts_D, X = counts_X, I = counts_I))
}

# Apply the function to the Original column in the data frame
character_counts <- t(sapply(New_table$col5, count_characters))

# Create new columns for counts of 'D', 'X', and 'I'
New_table$D_Count <- character_counts[, "D"]
New_table$X_Count <- character_counts[, "X"]
New_table$I_Count <- character_counts[, "I"]


#filter based on read count. Less than 5 reads is not enough to confidently say the read is real
#New_table = subset(New_table, col4 >= 5)

New_table = New_table[,c("lib","plant_material","PED_Target","aliases","SRU", "Plate_Name","project","pedigree","DNA","deletion","col4","read_percent","Reads_per_target","col2","D_Count","PRS_RES_DEL","col3","col5","col6")] #"del_window" in the c()
library(dplyr)
New_table = New_table %>%
  rename("prs" = "col2",
         "reads" = "col4",
         "rmrna"="col3",
         "cigar_number" ="col5",
         "cigar_sequence"= "col6",
         "library_ID" = "lib",
         "plate_ID" = "project",
         "alias" = "aliases",
         "plant_material_ID" = "plant_material",
  )
#replace NA with WT
New_table$deletion[is.na(New_table$deletion)] = "WT"
#Legit read caller
# Add a new column based on conditions
New_table$Legit_Read <- ifelse(New_table$read_percent > 8 & New_table$reads > 8, "yes", "no")

data = New_table

# Step 1: Create a merged column
data$merged_column <- paste(data$plant_material_ID, data$prs, sep = "_")

# Define a function to process each group
process_group <- function(df) {
  df <- df[order(-df$read_percent), ]  # Sort by reads in descending order
  top_reads_sum <- sum(head(df$read_percent, 2))  # Sum of the two largest reads values
  if (top_reads_sum >= 75) {
    return(head(df, 2))  # Keep top two rows if sum >= 75
  } else {
    return(head(df, 4))  # Keep top four rows if sum < 75
  }
}

# Apply the function to each group and combine results
filtered_data <- data %>%
  group_by(merged_column) %>%
  group_modify(~process_group(.x)) %>%
  ungroup()

# Print the first few rows of the filtered data to check
#print(head(filtered_data))


# Apply the function to each group, remove the merged column, and combine results
filtered_data <- data %>%
  group_by(merged_column) %>%
  group_modify(~process_group(.x)) %>%
  ungroup() %>%
  select(-merged_column)  # Remove the merged column


# Prepare and clean the data columns
filtered_data <- mutate(filtered_data,
                        deletion = as.numeric(as.character(deletion)),
                        FS_edit = ifelse(is.na(deletion), "No", ifelse(deletion %% 3 == 0, "No", "Yes")),
                        Rec8_Edited = ifelse(prs == "PRS078" & !is.na(deletion) & deletion != 3, "Yes", "No"),
                        Spo11_Edited = ifelse(prs == "PRS257" & !is.na(deletion) & !grepl("6D2017", cigar_number), "Yes", "No"))

# Summarize Full_FS by library_ID and prs
summary_data <- filtered_data %>%
  group_by(library_ID, prs) %>%
  summarize(Full_FS = ifelse(all(FS_edit == "Yes", na.rm = TRUE), "Yes", "No"), .groups = 'drop')

# Join the summary data back to the original data
filtered_data <- left_join(filtered_data, summary_data, by = c("library_ID", "prs"))

# Calculate conditions for each PRS under inspection
prs_summary <- filtered_data %>%
  group_by(library_ID, prs) %>%
  summarize(
    meets_condition = case_when(
      prs == "PRS078" & all(Rec8_Edited == "Yes", na.rm = TRUE) ~ TRUE,
      prs == "PRS257" & all(Spo11_Edited == "Yes", na.rm = TRUE) ~ TRUE,
      !(prs %in% c("PRS078", "PRS257")) & all(Full_FS == "Yes", na.rm = TRUE) ~ TRUE,
      TRUE ~ FALSE
    ),
    .groups = 'drop'
  ) %>%
  filter(meets_condition)  # Keep only rows where conditions are met

# Create a column with the unique responsible PRS codes
PRS_data <- prs_summary %>%
  group_by(library_ID) %>%
  summarize(
    Responsible_PRS = paste(unique(prs), collapse = ", "),
    .groups = 'drop'
  )

# Join the Responsible_PRS column back to the original dataset
PRS_data <- left_join(filtered_data, PRS_data, by = "library_ID")


keeper_data <- PRS_data %>%
  group_by(library_ID) %>%
  summarize(
    # Check for the presence of PRS codes and compute conditions only if present
    target_prs_all_yes = any((prs %in% c("PRS658", "PRS651", "PRS653")) & (Full_FS == "Yes")),
    rec8_present = any(prs == "PRS078"),  # Verify presence of PRS078
    rec8_all_yes = ifelse(rec8_present, all(Rec8_Edited[prs == "PRS078"] == "Yes", na.rm = TRUE), FALSE),
    has_prs239 = any(prs == "PRS239"),
    has_prs257 = any(prs == "PRS257"),
    prs239_all_yes = ifelse(has_prs239, any(prs == "PRS239" & Full_FS == "Yes"), FALSE),
    prs257_all_spo11_yes = ifelse(has_prs257, all(Spo11_Edited[prs == "PRS257"] == "Yes", na.rm = TRUE), FALSE),
    spo11_or_prs239_yes = prs239_all_yes | prs257_all_spo11_yes,
    # Check that all conditions are met and all required groups are covered
    all_conditions_met = target_prs_all_yes & (rec8_present & rec8_all_yes) & (has_prs239 | has_prs257) & spo11_or_prs239_yes,
    .groups = 'drop'
  ) %>%
  filter(all_conditions_met) %>%
  mutate(Keeper = "TableSpark") %>%
  select(library_ID, Keeper)



# Join the Keeper label back to the original dataset
final_data <- left_join(PRS_data, keeper_data, by = "library_ID") %>%
  mutate(Keeper = ifelse(is.na(Keeper), "", Keeper))

#View(New_table)
#Below apply() was code used before when generating the .csv's. Looks like it is unnecessary so I have archived it. ChatGPT artifact
#final_data = apply(filtered_data,2,as.character)
final_data$deletion[is.na(final_data$deletion)] = "WT"
#write csv
#csv to current directory
write.csv(final_data, "SRU080-custom_Report_Filtered_240920.csv", row.names = FALSE)
#write csv to chap folder in google drive
#Your path to Ohalo Google Drive
path_out = '/Users/alanrodriguez/Google Drive/Shared drives/Ohalo Molecular Bio/chap/SRU080-custom/'
write.csv(final_data,paste(path_out,'SRU080-custom_Report_Filtered_240920.csv',sep = ''),row.names = FALSE)
